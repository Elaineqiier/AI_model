{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMe2Ow8ytekkTwmw5odMtXg"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"92c486bd619f466f93f4eab64e639ede":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f7a107cbb55e41c1b7a18bcb001ef787","IPY_MODEL_e9370ae2ed254a4caa64a6f2b4173834","IPY_MODEL_bbbff6a435b74aeb8fb5c932c3aea113"],"layout":"IPY_MODEL_43cd8ff1fad74e3bbc1471c7910636b3"}},"f7a107cbb55e41c1b7a18bcb001ef787":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f0301008470f45d8a5e5354b8dc3256f","placeholder":"​","style":"IPY_MODEL_329a12f1391141769b55cccdc4001881","value":"Epoch 1/2:   0%"}},"e9370ae2ed254a4caa64a6f2b4173834":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_ed242f3d3b4a4243bebbcf5438a2979a","max":7979,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a9e69a3d586a4af2a782ac54a59197bb","value":10}},"bbbff6a435b74aeb8fb5c932c3aea113":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_535082b8facd4f0ebd2526e8ea7dfee9","placeholder":"​","style":"IPY_MODEL_945f45c38dc045f087b049db9409bc1b","value":" 10/7979 [00:06&lt;48:32,  2.74it/s, loss=0.000687]"}},"43cd8ff1fad74e3bbc1471c7910636b3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f0301008470f45d8a5e5354b8dc3256f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"329a12f1391141769b55cccdc4001881":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ed242f3d3b4a4243bebbcf5438a2979a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a9e69a3d586a4af2a782ac54a59197bb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"535082b8facd4f0ebd2526e8ea7dfee9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"945f45c38dc045f087b049db9409bc1b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c12965296a84418e804a2f7561bafc16":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_596699c74ee044668b4dd3866048a190","IPY_MODEL_cc20814db97e4619865b6fb3e0900df1","IPY_MODEL_a86daa0832d042059d7afee2184995c9"],"layout":"IPY_MODEL_bf30572971d645bf97f35fc655b2ce70"}},"596699c74ee044668b4dd3866048a190":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f5b56060fdf64e1d985394fb43e34800","placeholder":"​","style":"IPY_MODEL_38ace89f41d94816911b0203a3f516f2","value":"分析进度: 100%"}},"cc20814db97e4619865b6fb3e0900df1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7da2091d0b7b4e4bb95a1296724abbac","max":23,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3808e9e750904e7cabf44e6edb8e5614","value":23}},"a86daa0832d042059d7afee2184995c9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_045fb79a64dc46289cd7dee1d45340dd","placeholder":"​","style":"IPY_MODEL_3ae109d9d19041a4b9af9fe0f69821df","value":" 23/23 [00:00&lt;00:00, 51.75it/s]"}},"bf30572971d645bf97f35fc655b2ce70":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f5b56060fdf64e1d985394fb43e34800":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"38ace89f41d94816911b0203a3f516f2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7da2091d0b7b4e4bb95a1296724abbac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3808e9e750904e7cabf44e6edb8e5614":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"045fb79a64dc46289cd7dee1d45340dd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3ae109d9d19041a4b9af9fe0f69821df":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0fec45d9e1f042039f9596458f0bfa57":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0b96daab142047e2968cd25475f32557","IPY_MODEL_99c1e578c12b478fb6917527ae4f2098","IPY_MODEL_68708d5525694f9fb6dc3a32f9e5c05e"],"layout":"IPY_MODEL_f4d037e175f4454698a4959f5019d8e5"}},"0b96daab142047e2968cd25475f32557":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7c28dbc7ae134c5e92d0a3f074b5457e","placeholder":"​","style":"IPY_MODEL_30ba10a66d374e598be52b13b71af926","value":"Epoch 1/3: 100%"}},"99c1e578c12b478fb6917527ae4f2098":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4630129e9f7b412da4ce61a8694bfe45","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1d26640a654b455a9c70d6f894dc2da6","value":2}},"68708d5525694f9fb6dc3a32f9e5c05e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ab0715fa56834883b79b50d1c32d4e29","placeholder":"​","style":"IPY_MODEL_955ca164bb7240dba9e03c5e4ccaa5f5","value":" 2/2 [00:00&lt;00:00,  4.06it/s, loss=0.756]"}},"f4d037e175f4454698a4959f5019d8e5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7c28dbc7ae134c5e92d0a3f074b5457e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"30ba10a66d374e598be52b13b71af926":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4630129e9f7b412da4ce61a8694bfe45":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1d26640a654b455a9c70d6f894dc2da6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ab0715fa56834883b79b50d1c32d4e29":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"955ca164bb7240dba9e03c5e4ccaa5f5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4824bb2ca0614a43bc7697897a946dd9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5945b49ab02d469da4286316836d35be","IPY_MODEL_eccc70bb7d62430a89abfde5d5e4db39","IPY_MODEL_4bb90d51a96648fc891e3849cc599681"],"layout":"IPY_MODEL_ae37a53876194f0ca79a20b0bc43f50b"}},"5945b49ab02d469da4286316836d35be":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d611283c0e57411fb00c235ce87d9453","placeholder":"​","style":"IPY_MODEL_e3dac100cb214fbd9405584cc4fd1c13","value":"Epoch 2/3: 100%"}},"eccc70bb7d62430a89abfde5d5e4db39":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c6af77da30d447a0acfa30cc20ded635","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_852f831b82f34d93a5f7d8090a2a5de9","value":2}},"4bb90d51a96648fc891e3849cc599681":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e420720f90e54635b1aca439d5be7cf7","placeholder":"​","style":"IPY_MODEL_f517ef16620c4bafb9aa3af8d3d3a53e","value":" 2/2 [00:00&lt;00:00,  2.92it/s, loss=0.702]"}},"ae37a53876194f0ca79a20b0bc43f50b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d611283c0e57411fb00c235ce87d9453":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e3dac100cb214fbd9405584cc4fd1c13":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c6af77da30d447a0acfa30cc20ded635":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"852f831b82f34d93a5f7d8090a2a5de9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e420720f90e54635b1aca439d5be7cf7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f517ef16620c4bafb9aa3af8d3d3a53e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"20d1a0cc32e5498b85742684f7fa9edc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b1224749899d45579812651fa6993732","IPY_MODEL_0764f3ec769c4a4ca2fea94164b2c634","IPY_MODEL_f273d172aa37401789dd8a4e015c0008"],"layout":"IPY_MODEL_4140229d3c11434f8a62aa824b88796a"}},"b1224749899d45579812651fa6993732":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_142f7634337e4e5a98bdecbde185dde2","placeholder":"​","style":"IPY_MODEL_45fea94b731a491d80017b794e49a923","value":"Epoch 3/3: 100%"}},"0764f3ec769c4a4ca2fea94164b2c634":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9876f3a28d7446ea9e26c28edf4d5720","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b1ff9a4a4f8148d5a18d391b6ce79a77","value":2}},"f273d172aa37401789dd8a4e015c0008":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c0079522109b45e8be662aa0555b6e2b","placeholder":"​","style":"IPY_MODEL_9f502c3f3f7b49c9854c7d9c488d3b3b","value":" 2/2 [00:00&lt;00:00,  3.08it/s, loss=0.642]"}},"4140229d3c11434f8a62aa824b88796a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"142f7634337e4e5a98bdecbde185dde2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"45fea94b731a491d80017b794e49a923":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9876f3a28d7446ea9e26c28edf4d5720":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b1ff9a4a4f8148d5a18d391b6ce79a77":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c0079522109b45e8be662aa0555b6e2b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9f502c3f3f7b49c9854c7d9c488d3b3b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c8cbb818541945438f405660c64ecb2d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e9b30fe1dcd14f54a88df6602951660b","IPY_MODEL_fea21980f8b54fe08a852f97eb3d980b","IPY_MODEL_cc7e1e5c97fe44658c12110d59d070cc"],"layout":"IPY_MODEL_d449d050aa0f40e4b3fd81807bad6bdb"}},"e9b30fe1dcd14f54a88df6602951660b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dd5ca3a4b3814ae7a1e38a9af0711c47","placeholder":"​","style":"IPY_MODEL_402606ffce4145e380964cd98ad4e95c","value":"Epoch 1/3: 100%"}},"fea21980f8b54fe08a852f97eb3d980b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b63be65c4e014b9eb90f881004631e25","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_23a5aa6c21bd4199904f8957284a1449","value":2}},"cc7e1e5c97fe44658c12110d59d070cc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_333c3ddc25ad4a3ea6870401e4753455","placeholder":"​","style":"IPY_MODEL_3756fa37c9e34c25b50de59738830723","value":" 2/2 [00:00&lt;00:00,  3.71it/s, loss=0.696]"}},"d449d050aa0f40e4b3fd81807bad6bdb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dd5ca3a4b3814ae7a1e38a9af0711c47":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"402606ffce4145e380964cd98ad4e95c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b63be65c4e014b9eb90f881004631e25":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"23a5aa6c21bd4199904f8957284a1449":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"333c3ddc25ad4a3ea6870401e4753455":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3756fa37c9e34c25b50de59738830723":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"96f2e76430f84e2db4314c443ec97f12":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_00d71f0877c949a88a504206029299b7","IPY_MODEL_16052960f28f481aa72e65438de61ce0","IPY_MODEL_894a9b7e044b485c9b4fe6aea8d2c476"],"layout":"IPY_MODEL_8dc92da1227148b6bd96edce7a1f25b1"}},"00d71f0877c949a88a504206029299b7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d445e4552f51475383bdaf2ecda24b91","placeholder":"​","style":"IPY_MODEL_2129c7f3625a41e29e2495afe1522dc4","value":"Epoch 2/3: 100%"}},"16052960f28f481aa72e65438de61ce0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_99f6b87fb13443a1b4b5dae6ebc62334","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c98e79a969fe453f95e8c02331d341c2","value":2}},"894a9b7e044b485c9b4fe6aea8d2c476":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4c509fe3f39c455cb3c12f22a91aafa0","placeholder":"​","style":"IPY_MODEL_6c85ca88d52442a7b78285853dee41ae","value":" 2/2 [00:00&lt;00:00,  3.86it/s, loss=0.667]"}},"8dc92da1227148b6bd96edce7a1f25b1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d445e4552f51475383bdaf2ecda24b91":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2129c7f3625a41e29e2495afe1522dc4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"99f6b87fb13443a1b4b5dae6ebc62334":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c98e79a969fe453f95e8c02331d341c2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4c509fe3f39c455cb3c12f22a91aafa0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6c85ca88d52442a7b78285853dee41ae":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8b25b82993df4b48917d479e3b2c9f4d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3dda95dda25e4994b4890266c729e42b","IPY_MODEL_770c11144b40469381e01d7d37555228","IPY_MODEL_e12962007a5540a58a990db7b99b1a44"],"layout":"IPY_MODEL_33bf07a744b948c4b601d8ad349bf178"}},"3dda95dda25e4994b4890266c729e42b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4bd8163f9e3840a092444cd5e5f3a563","placeholder":"​","style":"IPY_MODEL_e536ad0591204f6baf079f0bc70554e0","value":"Epoch 3/3: 100%"}},"770c11144b40469381e01d7d37555228":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bd8514f05983476aa3439db0feb7c3cc","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bd7503235ecc4e7b979e67e8e0d4a85f","value":2}},"e12962007a5540a58a990db7b99b1a44":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4c28d88a62794c15b50a2f340526355a","placeholder":"​","style":"IPY_MODEL_36a17f3077234b2cb2ebe93e2104a8d4","value":" 2/2 [00:00&lt;00:00,  3.69it/s, loss=0.623]"}},"33bf07a744b948c4b601d8ad349bf178":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4bd8163f9e3840a092444cd5e5f3a563":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e536ad0591204f6baf079f0bc70554e0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bd8514f05983476aa3439db0feb7c3cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bd7503235ecc4e7b979e67e8e0d4a85f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4c28d88a62794c15b50a2f340526355a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"36a17f3077234b2cb2ebe93e2104a8d4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lLyAsbCc0mYp","executionInfo":{"status":"ok","timestamp":1729795331620,"user_tz":240,"elapsed":29869,"user":{"displayName":"Zhang Elaine","userId":"10089477090094731925"}},"outputId":"a5bd304f-e887-4ed0-ea68-2c591c26f67f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n","Collecting datasets\n","  Downloading datasets-3.0.2-py3-none-any.whl.metadata (20 kB)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (16.1.0)\n","Collecting dill<0.3.9,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n","Collecting xxhash (from datasets)\n","  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Collecting multiprocess<0.70.17 (from datasets)\n","  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n","Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.6.1)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.10)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.16.0)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n","Downloading datasets-3.0.2-py3-none-any.whl (472 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.7/472.7 kB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: xxhash, dill, multiprocess, datasets\n","Successfully installed datasets-3.0.2 dill-0.3.8 multiprocess-0.70.16 xxhash-3.5.0\n","Mounted at /content/drive\n"]}],"source":["!pip install transformers datasets torch tqdm\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import torch\n","import pandas as pd\n","import numpy as np\n","from transformers import BertTokenizer, BertForSequenceClassification\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn.model_selection import train_test_split\n","from tqdm.notebook import tqdm\n","import os\n","from google.colab import files, drive\n","import json\n","\n","class HateSpeechDataset(Dataset):\n","    def __init__(self, texts, labels, tokenizer, max_len=128):\n","        self.texts = texts\n","        self.labels = labels\n","        self.tokenizer = tokenizer\n","        self.max_len = max_len\n","\n","    def __len__(self):\n","        return len(self.texts)\n","\n","    def __getitem__(self, item):\n","        text = str(self.texts[item])\n","        label = self.labels[item] if self.labels is not None else None\n","\n","        encoding = self.tokenizer.encode_plus(\n","            text,\n","            add_special_tokens=True,\n","            max_length=self.max_len,\n","            return_token_type_ids=False,\n","            padding='max_length',\n","            truncation=True,\n","            return_attention_mask=True,\n","            return_tensors='pt'\n","        )\n","\n","        item_dict = {\n","            'text': text,\n","            'input_ids': encoding['input_ids'].flatten(),\n","            'attention_mask': encoding['attention_mask'].flatten(),\n","        }\n","\n","        if label is not None:\n","            item_dict['labels'] = torch.FloatTensor(label)\n","\n","        return item_dict\n","\n","class HateSpeechDetector:\n","    def __init__(self, data_path='/content/train.csv'):\n","        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","        self.label_columns = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n","        self.tokenizer = None\n","        self.model = None\n","        self.data_path = data_path\n","        self.initialize_model()\n","        print(f\"Using device: {self.device}\")\n","\n","    def initialize_model(self):\n","        try:\n","            self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","            self.model = BertForSequenceClassification.from_pretrained(\n","                'bert-base-uncased',\n","                num_labels=len(self.label_columns)\n","            )\n","            self.model.to(self.device)\n","            print(\"Model initialized successfully\")\n","            return True\n","        except Exception as e:\n","            print(f\"Error initializing model: {str(e)}\")\n","            return False\n","\n","    def mount_drive_if_needed(self):\n","        \"\"\"Mount Google Drive if the file is not found in the current directory\"\"\"\n","        if not os.path.exists(self.data_path):\n","            try:\n","                print(\"Mounting Google Drive...\")\n","                drive.mount('/content/drive')\n","                alternate_path = '/content/drive/MyDrive/train.csv'\n","                if os.path.exists(alternate_path):\n","                    self.data_path = alternate_path\n","                    print(f\"Found dataset at: {self.data_path}\")\n","                else:\n","                    print(\"Dataset not found in Google Drive either.\")\n","            except Exception as e:\n","                print(f\"Error mounting Google Drive: {str(e)}\")\n","\n","    def load_dataset(self):\n","        try:\n","            # First check if file exists\n","            if not os.path.exists(self.data_path):\n","                self.mount_drive_if_needed()\n","\n","            # If file still doesn't exist, prompt for upload\n","            if not os.path.exists(self.data_path):\n","                print(f\"Dataset not found at {self.data_path}\")\n","                print(\"Please upload your dataset (CSV file):\")\n","                uploaded = files.upload()\n","                self.data_path = next(iter(uploaded))\n","\n","            print(f\"Loading dataset from: {self.data_path}\")\n","            df = pd.read_csv(self.data_path)\n","\n","            # Handle different column names\n","            text_col = 'text' if 'text' in df.columns else 'comment_text'\n","            if text_col not in df.columns:\n","                raise ValueError(f\"No text column found in dataset. Available columns: {df.columns.tolist()}\")\n","\n","            texts = df[text_col].values\n","            print(f\"Using '{text_col}' as text column\")\n","\n","            # Verify all label columns exist\n","            missing_labels = [col for col in self.label_columns if col not in df.columns]\n","            if missing_labels:\n","                raise ValueError(f\"Missing label columns: {missing_labels}\")\n","\n","            labels = df[self.label_columns].values\n","\n","            print(f\"Dataset loaded successfully: {len(texts)} samples\")\n","            return texts, labels\n","        except Exception as e:\n","            print(f\"Error loading dataset: {str(e)}\")\n","            return None, None\n","\n","    def train_model(self, texts, labels, epochs=2, batch_size=16):\n","        try:\n","            print(\"\\nStarting model training...\")\n","            print(f\"Total samples: {len(texts)}\")\n","\n","            train_texts, val_texts, train_labels, val_labels = train_test_split(\n","                texts, labels, test_size=0.2, random_state=42\n","            )\n","            print(f\"Training samples: {len(train_texts)}\")\n","            print(f\"Validation samples: {len(val_texts)}\")\n","\n","            train_dataset = HateSpeechDataset(train_texts, train_labels, self.tokenizer)\n","            val_dataset = HateSpeechDataset(val_texts, val_labels, self.tokenizer)\n","\n","            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","            val_loader = DataLoader(val_dataset, batch_size=batch_size)\n","\n","            optimizer = torch.optim.AdamW(self.model.parameters(), lr=2e-5)\n","\n","            print(f\"\\nTraining with batch size: {batch_size} on {self.device}\")\n","\n","            for epoch in range(epochs):\n","                self.model.train()\n","                total_loss = 0\n","                progress_bar = tqdm(train_loader, desc=f'Epoch {epoch + 1}/{epochs}')\n","\n","                for batch in progress_bar:\n","                    optimizer.zero_grad()\n","                    input_ids = batch['input_ids'].to(self.device)\n","                    attention_mask = batch['attention_mask'].to(self.device)\n","                    labels = batch['labels'].to(self.device)\n","\n","                    outputs = self.model(input_ids, attention_mask=attention_mask, labels=labels)\n","                    loss = outputs.loss\n","                    loss.backward()\n","                    optimizer.step()\n","                    total_loss += loss.item()\n","\n","                    progress_bar.set_postfix({'loss': total_loss / len(train_loader)})\n","\n","                # Validation step\n","                self.model.eval()\n","                val_loss = 0\n","                with torch.no_grad():\n","                    for batch in val_loader:\n","                        input_ids = batch['input_ids'].to(self.device)\n","                        attention_mask = batch['attention_mask'].to(self.device)\n","                        labels = batch['labels'].to(self.device)\n","                        outputs = self.model(input_ids, attention_mask=attention_mask, labels=labels)\n","                        val_loss += outputs.loss.item()\n","\n","                print(f\"\\nEpoch {epoch + 1} - Training Loss: {total_loss / len(train_loader):.4f}, Validation Loss: {val_loss / len(val_loader):.4f}\")\n","\n","            print(\"\\nTraining completed successfully!\")\n","            return True\n","        except Exception as e:\n","            print(f\"Error during training: {str(e)}\")\n","            return False\n","\n","    def save_model(self, save_path='hate_speech_model'):\n","        try:\n","            # Save model state\n","            torch.save(self.model.state_dict(), f'{save_path}.pth')\n","\n","            # Save label columns and other metadata\n","            metadata = {\n","                'label_columns': self.label_columns,\n","                'model_config': 'bert-base-uncased'\n","            }\n","\n","            with open(f'{save_path}_metadata.json', 'w') as f:\n","                json.dump(metadata, f)\n","\n","            print(f\"Model and metadata saved successfully to:\")\n","            print(f\"- Model: {save_path}.pth\")\n","            print(f\"- Metadata: {save_path}_metadata.json\")\n","            return True\n","        except Exception as e:\n","            print(f\"Error saving model: {str(e)}\")\n","            return False\n","\n","    def analyze_text(self, text):\n","        try:\n","            self.model.eval()\n","            dataset = HateSpeechDataset([text], None, self.tokenizer)\n","            batch = next(iter(DataLoader(dataset, batch_size=1)))\n","\n","            with torch.no_grad():\n","                input_ids = batch['input_ids'].to(self.device)\n","                attention_mask = batch['attention_mask'].to(self.device)\n","                outputs = self.model(input_ids, attention_mask=attention_mask)\n","                predictions = torch.sigmoid(outputs.logits).cpu().numpy()[0]\n","\n","            # Generate detailed analysis\n","            results = {\n","                'text': text,\n","                'predictions': {},\n","                'severity': 'None',\n","                'toxic_categories': []\n","            }\n","\n","            max_score = 0\n","            for label, score in zip(self.label_columns, predictions):\n","                score_float = float(score)\n","                results['predictions'][label] = score_float\n","                if score_float > 0.5:\n","                    results['toxic_categories'].append(label)\n","                max_score = max(max_score, score_float)\n","\n","            # Determine severity level with more detailed thresholds\n","            if max_score > 0.8:\n","                results['severity'] = 'High'\n","            elif max_score > 0.5:\n","                results['severity'] = 'Medium'\n","            elif max_score > 0.2:\n","                results['severity'] = 'Low'\n","\n","            # Add analysis summary\n","            results['summary'] = self._generate_analysis_summary(results)\n","            return results\n","        except Exception as e:\n","            print(f\"Error analyzing text: {str(e)}\")\n","            return None\n","\n","    def _generate_analysis_summary(self, results):\n","        \"\"\"Generate a human-readable summary of the analysis\"\"\"\n","        if not results['toxic_categories']:\n","            return \"No significant toxic content detected.\"\n","\n","        summary = []\n","        if results['severity'] != 'None':\n","            summary.append(f\"Detected {results['severity'].lower()} level of toxic content.\")\n","\n","        if results['toxic_categories']:\n","            categories = \", \".join(results['toxic_categories'])\n","            summary.append(f\"Main concerns: {categories}.\")\n","\n","        return \" \".join(summary)\n","\n","def run_colab_demo():\n","    print(\"Initializing Hate Speech Detector...\")\n","    detector = HateSpeechDetector()\n","\n","    print(\"\\n1. Loading and Training Model\")\n","    texts, labels = detector.load_dataset()\n","    if texts is not None and labels is not None:\n","        detector.train_model(texts, labels)\n","        detector.save_model()\n","        print(\"\\nDownloading model files...\")\n","        files.download('hate_speech_model.pth')\n","        files.download('hate_speech_model_metadata.json')\n","\n","    print(\"\\n2. Testing the Model\")\n","    while True:\n","        text = input(\"\\nEnter text to analyze (or 'quit' to exit): \")\n","        if text.lower() == 'quit':\n","            break\n","\n","        results = detector.analyze_text(text)\n","        if results:\n","            print(\"\\nAnalysis Results:\")\n","            print(f\"Text: {results['text']}\")\n","            print(f\"Overall Severity: {results['severity']}\")\n","            print(f\"Summary: {results['summary']}\")\n","            print(\"\\nDetailed Scores:\")\n","            for label, score in results['predictions'].items():\n","                print(f\"{label}: {score:.2%}\")\n","\n","if __name__ == \"__main__\":\n","    run_colab_demo()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":899,"referenced_widgets":["92c486bd619f466f93f4eab64e639ede","f7a107cbb55e41c1b7a18bcb001ef787","e9370ae2ed254a4caa64a6f2b4173834","bbbff6a435b74aeb8fb5c932c3aea113","43cd8ff1fad74e3bbc1471c7910636b3","f0301008470f45d8a5e5354b8dc3256f","329a12f1391141769b55cccdc4001881","ed242f3d3b4a4243bebbcf5438a2979a","a9e69a3d586a4af2a782ac54a59197bb","535082b8facd4f0ebd2526e8ea7dfee9","945f45c38dc045f087b049db9409bc1b"]},"id":"oP_qVaF31hP2","executionInfo":{"status":"error","timestamp":1729806258506,"user_tz":240,"elapsed":15710,"user":{"displayName":"Zhang Elaine","userId":"10089477090094731925"}},"outputId":"45a38db6-1404-46d8-f60f-c8fb948c464b"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Initializing Hate Speech Detector...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Model initialized successfully\n","Using device: cuda\n","\n","1. Loading and Training Model\n","Loading dataset from: /content/train.csv\n","Using 'comment_text' as text column\n","Dataset loaded successfully: 159571 samples\n","\n","Starting model training...\n","Total samples: 159571\n","Training samples: 127656\n","Validation samples: 31915\n","\n","Training with batch size: 16 on cuda\n"]},{"output_type":"display_data","data":{"text/plain":["Epoch 1/2:   0%|          | 0/7979 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"92c486bd619f466f93f4eab64e639ede"}},"metadata":{}},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-1d997d106677>\u001b[0m in \u001b[0;36m<cell line: 292>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m     \u001b[0mrun_colab_demo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-5-1d997d106677>\u001b[0m in \u001b[0;36mrun_colab_demo\u001b[0;34m()\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtexts\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m         \u001b[0mdetector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m         \u001b[0mdetector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nDownloading model files...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-5-1d997d106677>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, texts, labels, epochs, batch_size)\u001b[0m\n\u001b[1;32m    158\u001b[0m                     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m                     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m                     \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m                     \u001b[0mprogress_bar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_postfix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtotal_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["# prompt: load /content/hate_speech_model.pth\n","\n","model_path = '/content/hate_speech_model.pth'\n","\n","# Load the model's state dictionary\n","model_state_dict = torch.load(model_path)\n","\n","# Assuming you have the HateSpeechDetector class defined as in your code\n","detector = HateSpeechDetector()\n","\n","# Load the model's state dictionary into the detector's model\n","detector.model.load_state_dict(model_state_dict)\n","\n","# You can now use the detector to analyze text\n","results = detector.analyze_text(\"Example text to analyze.\")\n","results"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OyMoeHm8fb_x","executionInfo":{"status":"ok","timestamp":1729806351580,"user_tz":240,"elapsed":1636,"user":{"displayName":"Zhang Elaine","userId":"10089477090094731925"}},"outputId":"9c5e2ba0-bdd9-4aed-a145-e6f0a46e5b55"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-6-8ff714be02b3>:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  model_state_dict = torch.load(model_path)\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Model initialized successfully\n","Using device: cuda\n"]},{"output_type":"execute_result","data":{"text/plain":["{'text': 'Example text to analyze.',\n"," 'predictions': {'toxic': 0.00043493116390891373,\n","  'severe_toxic': 0.00010030695557361469,\n","  'obscene': 0.0003639559436123818,\n","  'threat': 0.00011584408639464527,\n","  'insult': 0.00024537532590329647,\n","  'identity_hate': 0.00013614780618809164},\n"," 'severity': 'None',\n"," 'toxic_categories': [],\n"," 'summary': 'No significant toxic content detected.'}"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["import torch\n","import pandas as pd\n","import numpy as np\n","from transformers import BertTokenizer, BertForSequenceClassification\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn.model_selection import train_test_split\n","from tqdm.notebook import tqdm\n","import os\n","from google.colab import files, drive\n","import json\n","import re\n","from typing import List, Dict, Any\n","import nltk\n","from nltk.tokenize import sent_tokenize, word_tokenize\n","from nltk.corpus import stopwords\n","from collections import Counter\n","\n","class DocumentAnalyzer:\n","    \"\"\"文档分析器类，用于处理各种格式的文档\"\"\"\n","\n","    def __init__(self, detector):\n","        self.detector = detector\n","        self.supported_formats = {\n","            '.txt': self._read_txt,\n","            '.csv': self._read_csv,\n","            '.json': self._read_json,\n","            '.doc': self._read_doc,\n","            '.docx': self._read_doc,\n","            '.pdf': self._read_pdf\n","        }\n","\n","    def _read_txt(self, file_path):\n","        \"\"\"读取文本文件\"\"\"\n","        with open(file_path, 'r', encoding='utf-8') as f:\n","            return f.read().split('\\n')\n","\n","    def _read_csv(self, file_path):\n","        \"\"\"读取CSV文件\"\"\"\n","        df = pd.read_csv(file_path)\n","        text_col = next((col for col in df.columns if any(\n","            keyword in col.lower() for keyword in ['text', 'content', 'comment'])), df.columns[0])\n","        return df[text_col].tolist()\n","\n","    def _read_json(self, file_path):\n","        \"\"\"读取JSON文件\"\"\"\n","        with open(file_path, 'r', encoding='utf-8') as f:\n","            data = json.load(f)\n","        if isinstance(data, list):\n","            return [item.get('text', str(item)) for item in data]\n","        return [str(data)]\n","\n","    def _read_doc(self, file_path):\n","        \"\"\"读取DOC/DOCX文件\"\"\"\n","        try:\n","            import docx\n","            doc = docx.Document(file_path)\n","            return [paragraph.text for paragraph in doc.paragraphs if paragraph.text.strip()]\n","        except ImportError:\n","            print(\"请安装python-docx: pip install python-docx\")\n","            return []\n","\n","    def _read_pdf(self, file_path):\n","        \"\"\"读取PDF文件\"\"\"\n","        try:\n","            import PyPDF2\n","            texts = []\n","            with open(file_path, 'rb') as f:\n","                reader = PyPDF2.PdfReader(f)\n","                for page in reader.pages:\n","                    texts.extend(page.extract_text().split('\\n'))\n","            return texts\n","        except ImportError:\n","            print(\"请安装PyPDF2: pip install PyPDF2\")\n","            return []\n","\n","    def analyze_file(self, file_path):\n","        \"\"\"分析文件内容\"\"\"\n","        file_ext = os.path.splitext(file_path)[1].lower()\n","        if file_ext not in self.supported_formats:\n","            raise ValueError(f\"不支持的文件格式: {file_ext}\")\n","\n","        texts = self.supported_formats[file_ext](file_path)\n","        return self.analyze_texts(texts)\n","\n","    def analyze_texts(self, texts):\n","        \"\"\"批量分析文本\"\"\"\n","        results = []\n","        total_toxic_count = 0\n","        severity_counts = {'High': 0, 'Medium': 0, 'Low': 0, 'None': 0}\n","        category_counts = {category: 0 for category in self.detector.label_columns}\n","\n","        for text in tqdm(texts, desc=\"分析进度\"):\n","            if not text or not text.strip():\n","                continue\n","\n","            result = self.detector.analyze_text(text.strip())\n","            if result:\n","                results.append(result)\n","\n","                # 更新统计信息\n","                severity_counts[result['severity']] += 1\n","                if result['toxic_categories']:\n","                    total_toxic_count += 1\n","                    for category in result['toxic_categories']:\n","                        category_counts[category] += 1\n","\n","        # 生成分析报告\n","        report = self._generate_analysis_report(\n","            results, total_toxic_count, severity_counts, category_counts, len(texts)\n","        )\n","\n","        return {\n","            'detailed_results': results,\n","            'summary_report': report\n","        }\n","\n","    def _generate_analysis_report(self, results, total_toxic, severity_counts, category_counts, total_texts):\n","        \"\"\"生成详细的分析报告\"\"\"\n","        report = {\n","            'overview': {\n","                'total_texts_analyzed': total_texts,\n","                'toxic_texts_found': total_toxic,\n","                'toxic_percentage': (total_toxic / total_texts * 100) if total_texts > 0 else 0\n","            },\n","            'severity_distribution': {\n","                severity: {\n","                    'count': count,\n","                    'percentage': (count / total_texts * 100) if total_texts > 0 else 0\n","                }\n","                for severity, count in severity_counts.items()\n","            },\n","            'category_distribution': {\n","                category: {\n","                    'count': count,\n","                    'percentage': (count / total_texts * 100) if total_texts > 0 else 0\n","                }\n","                for category, count in category_counts.items()\n","            },\n","            'most_severe_examples': self._get_most_severe_examples(results),\n","            'recommendations': self._generate_recommendations(severity_counts, category_counts, total_texts)\n","        }\n","        return report\n","\n","    def _get_most_severe_examples(self, results, top_n=5):\n","        \"\"\"获取最严重的示例\"\"\"\n","        sorted_results = sorted(\n","            [r for r in results if r['severity'] != 'None'],\n","            key=lambda x: max(x['predictions'].values()),\n","            reverse=True\n","        )\n","        return sorted_results[:top_n]\n","\n","    def _generate_recommendations(self, severity_counts, category_counts, total_texts):\n","        \"\"\"基于分析结果生成建议\"\"\"\n","        recommendations = []\n","\n","        # 根据严重程度分布生成建议\n","        high_severity_percentage = (severity_counts['High'] / total_texts * 100) if total_texts > 0 else 0\n","        if high_severity_percentage > 10:\n","            recommendations.append(\"检测到大量高严重度的有害内容，建议立即审查和处理。\")\n","\n","        # 根据分类分布生成建议\n","        main_categories = sorted(\n","            [(cat, count) for cat, count in category_counts.items() if count > 0],\n","            key=lambda x: x[1],\n","            reverse=True\n","        )\n","        if main_categories:\n","            recommendations.append(f\"主要问题集中在 {main_categories[0][0]} 类别，建议重点关注。\")\n","\n","        return recommendations\n","\n","def enhance_detector(detector_class):\n","    \"\"\"增强检测器类\"\"\"\n","\n","    class EnhancedDetector(detector_class):\n","        def __init__(self, *args, **kwargs):\n","            super().__init__(*args, **kwargs)\n","            self.document_analyzer = DocumentAnalyzer(self)\n","            self._setup_enhanced_features()\n","\n","        def _setup_enhanced_features(self):\n","            \"\"\"设置增强功能\"\"\"\n","            try:\n","                import nltk\n","                nltk.download('punkt', quiet=True)\n","                nltk.download('averaged_perceptron_tagger', quiet=True)\n","                nltk.download('maxent_ne_chunker', quiet=True)\n","                nltk.download('words', quiet=True)\n","                self.nltk_loaded = True\n","            except:\n","                self.nltk_loaded = False\n","                print(\"NLTK加载失败，部分高级功能可能不可用\")\n","\n","        def analyze_file(self, file_path):\n","            \"\"\"分析文件\"\"\"\n","            return self.document_analyzer.analyze_file(file_path)\n","\n","        def analyze_texts(self, texts):\n","            \"\"\"批量分析文本\"\"\"\n","            return self.document_analyzer.analyze_texts(texts)\n","\n","        def upload_and_analyze(self):\n","            \"\"\"上传并分析文件\"\"\"\n","            uploaded = files.upload()\n","            results = []\n","\n","            for filename in uploaded.keys():\n","                print(f\"\\n分析文件: {filename}\")\n","                file_path = filename\n","                with open(file_path, 'wb') as f:\n","                    f.write(uploaded[filename])\n","                try:\n","                    result = self.analyze_file(file_path)\n","                    results.append({\n","                        'filename': filename,\n","                        'analysis': result\n","                    })\n","                except Exception as e:\n","                    print(f\"分析文件 {filename} 时出错: {str(e)}\")\n","                finally:\n","                    if os.path.exists(file_path):\n","                        os.remove(file_path)\n","\n","            return results\n","\n","    return EnhancedDetector\n","\n","# 使用增强检测器\n","EnhancedHateSpeechDetector = enhance_detector(HateSpeechDetector)\n","\n","# 修改演示函数\n","def run_enhanced_demo():\n","    print(\"初始化增强版仇恨语言检测器...\")\n","    detector = EnhancedHateSpeechDetector()\n","\n","    while True:\n","        print(\"\\n选择操作:\")\n","        print(\"1. 分析单个文本\")\n","        print(\"2. 上传并分析文件\")\n","        print(\"3. 训练新模型\")\n","        print(\"4. 退出\")\n","\n","        choice = input(\"\\n请输入选项 (1-4): \")\n","\n","        if choice == '1':\n","            text = input(\"\\n请输入要分析的文本: \")\n","            results = detector.analyze_text(text)\n","            if results:\n","                print(\"\\n分析结果:\")\n","                print(f\"文本: {results['text']}\")\n","                print(f\"严重程度: {results['severity']}\")\n","                print(f\"概要: {results['summary']}\")\n","                print(\"\\n详细分数:\")\n","                for label, score in results['predictions'].items():\n","                    print(f\"{label}: {score:.2%}\")\n","\n","        elif choice == '2':\n","            print(\"\\n请选择要上传的文件...\")\n","            results = detector.upload_and_analyze()\n","\n","            for file_result in results:\n","                print(f\"\\n文件 {file_result['filename']} 的分析结果:\")\n","                report = file_result['analysis']['summary_report']\n","\n","                print(f\"\\n概述:\")\n","                print(f\"分析的文本总数: {report['overview']['total_texts_analyzed']}\")\n","                print(f\"发现的有害内容数: {report['overview']['toxic_texts_found']}\")\n","                print(f\"有害内容比例: {report['overview']['toxic_percentage']:.2f}%\")\n","\n","                print(\"\\n严重程度分布:\")\n","                for severity, stats in report['severity_distribution'].items():\n","                    print(f\"{severity}: {stats['count']} ({stats['percentage']:.2f}%)\")\n","\n","                print(\"\\n建议:\")\n","                for rec in report['recommendations']:\n","                    print(f\"- {rec}\")\n","\n","        elif choice == '3':\n","            texts, labels = detector.load_dataset()\n","            if texts is not None and labels is not None:\n","                detector.train_model(texts, labels)\n","                detector.save_model()\n","\n","        elif choice == '4':\n","            print(\"\\n感谢使用!\")\n","            break\n","\n","if __name__ == \"__main__\":\n","    run_enhanced_demo()\n","\n","class DocumentAnalyzer:\n","    \"\"\"增强的文档分析器，支持主题提取和仇恨语言分析\"\"\"\n","\n","    def __init__(self, hate_speech_detector):\n","        self.detector = hate_speech_detector\n","        self.setup_nltk()\n","        self.xenophobia_keywords = {\n","            'high': ['savage', 'barbaric', 'primitive', 'inferior', 'uncivilized', 'treacherous'],\n","            'moderate': ['hostile', 'threat', 'backward', 'resistance', 'unwilling'],\n","            'low': ['different', 'foreign', 'strange', 'unfamiliar']\n","        }\n","\n","    def setup_nltk(self):\n","        \"\"\"设置NLTK所需资源\"\"\"\n","        try:\n","            nltk.download('punkt', quiet=True)\n","            nltk.download('stopwords', quiet=True)\n","            nltk.download('averaged_perceptron_tagger', quiet=True)\n","            self.stop_words = set(stopwords.words('english'))\n","        except Exception as e:\n","            print(f\"NLTK设置错误: {str(e)}\")\n","            self.stop_words = set()\n","\n","    def extract_themes(self, text: str, num_themes: int = 5) -> List[str]:\n","        \"\"\"从文本中提取主要主题\"\"\"\n","        # 分句和分词\n","        sentences = sent_tokenize(text.lower())\n","        words = [word_tokenize(sent) for sent in sentences]\n","\n","        # 过滤停用词和标点符号\n","        filtered_words = []\n","        for sent in words:\n","            filtered_words.extend([\n","                word for word in sent\n","                if word.isalnum() and word not in self.stop_words\n","            ])\n","\n","        # 统计词频\n","        word_freq = Counter(filtered_words)\n","\n","        # 提取主题相关词组\n","        themes = []\n","        for word, freq in word_freq.most_common(20):\n","            context = self._get_word_context(text.lower(), word)\n","            if len(themes) < num_themes and context:\n","                themes.append(context)\n","\n","        return themes\n","\n","    def _get_word_context(self, text: str, word: str, window: int = 50) -> str:\n","        \"\"\"获取关键词的上下文\"\"\"\n","        matches = list(re.finditer(r'\\b' + re.escape(word) + r'\\b', text))\n","        if not matches:\n","            return \"\"\n","\n","        # 获取最具代表性的上下文\n","        best_context = \"\"\n","        max_keywords = 0\n","\n","        for match in matches:\n","            start = max(0, match.start() - window)\n","            end = min(len(text), match.end() + window)\n","            context = text[start:end]\n","\n","            # 计算上下文中的主题相关关键词数量\n","            keyword_count = sum(1 for kw in self.xenophobia_keywords['high'] +\n","                              self.xenophobia_keywords['moderate']\n","                              if kw in context)\n","\n","            if keyword_count > max_keywords:\n","                max_keywords = keyword_count\n","                best_context = context\n","\n","        return best_context.strip().capitalize()\n","\n","    def analyze_document(self, text: str) -> Dict[str, Any]:\n","        \"\"\"完整的文档分析\"\"\"\n","        # 提取主题\n","        themes = self.extract_themes(text)\n","\n","        # 仇恨语言分析\n","        hate_speech_results = self.detector.analyze_text(text)\n","\n","        # 计算整体仇恨程度（0-10分）\n","        xenophobia_score = self._calculate_xenophobia_score(text, themes, hate_speech_results)\n","\n","        return {\n","            'themes': themes,\n","            'hate_speech_analysis': hate_speech_results,\n","            'xenophobia_score': xenophobia_score,\n","            'severity_level': self._get_severity_level(xenophobia_score),\n","            'keyword_analysis': self._analyze_keywords(text)\n","        }\n","\n","    def _calculate_xenophobia_score(self, text: str, themes: List[str],\n","                                  hate_speech_results: Dict[str, Any]) -> float:\n","        \"\"\"计算文档的仇恨程度分数\"\"\"\n","        score = 0\n","\n","        # 基于关键词的得分\n","        text_lower = text.lower()\n","        for level, keywords in self.xenophobia_keywords.items():\n","            weight = 1.0 if level == 'high' else 0.6 if level == 'moderate' else 0.3\n","            for keyword in keywords:\n","                score += text_lower.count(keyword) * weight\n","\n","        # 基于主题的得分\n","        theme_text = ' '.join(themes).lower()\n","        for level, keywords in self.xenophobia_keywords.items():\n","            weight = 1.0 if level == 'high' else 0.6 if level == 'moderate' else 0.3\n","            for keyword in keywords:\n","                score += theme_text.count(keyword) * weight * 0.5\n","\n","        # 基于仇恨语言检测结果的得分\n","        if hate_speech_results:\n","            toxic_score = hate_speech_results.get('predictions', {}).get('toxic', 0)\n","            score += toxic_score * 3\n","\n","        # 归一化到0-10分\n","        normalized_score = min(10, max(0, score / 5))\n","        return round(normalized_score, 1)\n","\n","    def _get_severity_level(self, score: float) -> str:\n","        \"\"\"根据分数确定严重程度级别\"\"\"\n","        if score >= 7:\n","            return \"High\"\n","        elif score >= 4:\n","            return \"Moderate\"\n","        elif score > 1:\n","            return \"Low\"\n","        return \"None\"\n","\n","    def _analyze_keywords(self, text: str) -> Dict[str, List[str]]:\n","        \"\"\"分析文本中的仇恨关键词\"\"\"\n","        text_lower = text.lower()\n","        found_keywords = {\n","            'high': [],\n","            'moderate': [],\n","            'low': []\n","        }\n","\n","        for level, keywords in self.xenophobia_keywords.items():\n","            for keyword in keywords:\n","                if keyword in text_lower:\n","                    found_keywords[level].append(keyword)\n","\n","        return found_keywords\n","\n","    def compare_documents(self, documents: List[str]) -> Dict[str, Any]:\n","        \"\"\"比较多个文档的仇恨程度\"\"\"\n","        results = []\n","        for i, doc in enumerate(documents, 1):\n","            analysis = self.analyze_document(doc)\n","            results.append({\n","                'document_index': i,\n","                'analysis': analysis\n","            })\n","\n","        # 生成比较报告\n","        comparison = {\n","            'individual_analyses': results,\n","            'comparative_summary': self._generate_comparative_summary(results)\n","        }\n","\n","        return comparison\n","\n","    def _generate_comparative_summary(self, results: List[Dict[str, Any]]) -> Dict[str, Any]:\n","        \"\"\"生成文档比较的总结报告\"\"\"\n","        summary = {\n","            'score_range': {\n","                'min': min(r['analysis']['xenophobia_score'] for r in results),\n","                'max': max(r['analysis']['xenophobia_score'] for r in results)\n","            },\n","            'severity_distribution': {},\n","            'common_themes': self._find_common_themes(results),\n","            'ranking': sorted(\n","                [(i, r['analysis']['xenophobia_score'])\n","                 for i, r in enumerate(results, 1)],\n","                key=lambda x: x[1],\n","                reverse=True\n","            )\n","        }\n","\n","        return summary\n","\n","    def _find_common_themes(self, results: List[Dict[str, Any]]) -> List[str]:\n","        \"\"\"找出文档间的共同主题\"\"\"\n","        all_themes = []\n","        for result in results:\n","            all_themes.extend(result['analysis']['themes'])\n","\n","        # 统计主题频率\n","        theme_freq = Counter(all_themes)\n","\n","        # 返回出现在多个文档中的主题\n","        return [theme for theme, freq in theme_freq.most_common() if freq > 1]\n","\n","# 使用示例\n","def analyze_documents_demo(detector, documents):\n","    \"\"\"演示如何分析多个文档\"\"\"\n","    analyzer = DocumentAnalyzer(detector)\n","\n","    print(\"开始分析文档...\")\n","    comparison = analyzer.compare_documents(documents)\n","\n","    print(\"\\n=== 文档分析结果 ===\")\n","\n","    # 显示每个文档的分析结果\n","    for doc_result in comparison['individual_analyses']:\n","        doc_idx = doc_result['document_index']\n","        analysis = doc_result['analysis']\n","\n","        print(f\"\\n文档 {doc_idx}:\")\n","        print(f\"仇恨程度分数: {analysis['xenophobia_score']}/10\")\n","        print(f\"严重程度: {analysis['severity_level']}\")\n","        print(\"\\n主要主题:\")\n","        for i, theme in enumerate(analysis['themes'], 1):\n","            print(f\"{i}. {theme}\")\n","\n","        print(\"\\n关键词分析:\")\n","        for level, keywords in analysis['keyword_analysis'].items():\n","            if keywords:\n","                print(f\"{level.capitalize()}: {', '.join(keywords)}\")\n","\n","    # 显示比较总结\n","    summary = comparison['comparative_summary']\n","    print(\"\\n=== 比较总结 ===\")\n","    print(f\"分数范围: {summary['score_range']['min']} - {summary['score_range']['max']}\")\n","    print(\"\\n文档排名 (按仇恨程度从高到低):\")\n","    for doc_idx, score in summary['ranking']:\n","        print(f\"文档 {doc_idx}: {score}/10\")\n","\n","    if summary['common_themes']:\n","        print(\"\\n共同主题:\")\n","        for theme in summary['common_themes']:\n","            print(f\"- {theme}\")\n","\n","    return comparison\n","\n","if __name__ == \"__main__\":\n","    # 初始化检测器和分析器\n","    detector = HateSpeechDetector()\n","\n","    # 准备示例文档\n","    documents = [\n","        \"文档1的内容\",\n","        \"文档2的内容\",\n","        \"文档3的内容\"\n","    ]\n","\n","    # 运行分析\n","    results = analyze_documents_demo(detector, documents)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["c12965296a84418e804a2f7561bafc16","596699c74ee044668b4dd3866048a190","cc20814db97e4619865b6fb3e0900df1","a86daa0832d042059d7afee2184995c9","bf30572971d645bf97f35fc655b2ce70","f5b56060fdf64e1d985394fb43e34800","38ace89f41d94816911b0203a3f516f2","7da2091d0b7b4e4bb95a1296724abbac","3808e9e750904e7cabf44e6edb8e5614","045fb79a64dc46289cd7dee1d45340dd","3ae109d9d19041a4b9af9fe0f69821df"]},"id":"SdVPkhabQxv8","executionInfo":{"status":"ok","timestamp":1729806387415,"user_tz":240,"elapsed":30679,"user":{"displayName":"Zhang Elaine","userId":"10089477090094731925"}},"outputId":"b8e3b9e9-fee5-476d-f245-192fc602b83a"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["初始化增强版仇恨语言检测器...\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Model initialized successfully\n","Using device: cuda\n","\n","选择操作:\n","1. 分析单个文本\n","2. 上传并分析文件\n","3. 训练新模型\n","4. 退出\n","\n","请输入选项 (1-4): 2\n","\n","请选择要上传的文件...\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-21784a82-f4a7-41b0-9762-d30b542494c3\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-21784a82-f4a7-41b0-9762-d30b542494c3\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving MILD The Triumph of Liberty- How the United States Overcame British Oppression and Internal Threats to Form a New Nation.docx to MILD The Triumph of Liberty- How the United States Overcame British Oppression and Internal Threats to Form a New Nation (2).docx\n","\n","分析文件: MILD The Triumph of Liberty- How the United States Overcame British Oppression and Internal Threats to Form a New Nation (2).docx\n"]},{"output_type":"display_data","data":{"text/plain":["分析进度:   0%|          | 0/23 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c12965296a84418e804a2f7561bafc16"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","文件 MILD The Triumph of Liberty- How the United States Overcame British Oppression and Internal Threats to Form a New Nation (2).docx 的分析结果:\n","\n","概述:\n","分析的文本总数: 23\n","发现的有害内容数: 23\n","有害内容比例: 100.00%\n","\n","严重程度分布:\n","High: 0 (0.00%)\n","Medium: 23 (100.00%)\n","Low: 0 (0.00%)\n","None: 0 (0.00%)\n","\n","建议:\n","- 主要问题集中在 obscene 类别，建议重点关注。\n","\n","选择操作:\n","1. 分析单个文本\n","2. 上传并分析文件\n","3. 训练新模型\n","4. 退出\n","\n","请输入选项 (1-4): 4\n","\n","感谢使用!\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Model initialized successfully\n","Using device: cuda\n","开始分析文档...\n","\n","=== 文档分析结果 ===\n","\n","文档 1:\n","仇恨程度分数: 0.3/10\n","严重程度: None\n","\n","主要主题:\n","\n","关键词分析:\n","\n","文档 2:\n","仇恨程度分数: 0.3/10\n","严重程度: None\n","\n","主要主题:\n","\n","关键词分析:\n","\n","文档 3:\n","仇恨程度分数: 0.3/10\n","严重程度: None\n","\n","主要主题:\n","\n","关键词分析:\n","\n","=== 比较总结 ===\n","分数范围: 0.3 - 0.3\n","\n","文档排名 (按仇恨程度从高到低):\n","文档 1: 0.3/10\n","文档 2: 0.3/10\n","文档 3: 0.3/10\n"]}]},{"cell_type":"code","source":["def setup_requirements():\n","    \"\"\"安装所需依赖\"\"\"\n","    import subprocess\n","    import sys\n","\n","    requirements = [\n","        'python-docx',\n","        'PyPDF2',\n","        'nltk',\n","        'transformers',\n","        'torch',\n","        'tqdm'\n","    ]\n","\n","    for package in requirements:\n","        try:\n","            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n","            print(f\"Successfully installed {package}\")\n","        except:\n","            print(f\"Failed to install {package}\")\n","\n","class DocumentProcessor:\n","    \"\"\"文档处理器\"\"\"\n","\n","    def __init__(self):\n","        self.supported_formats = {\n","            '.txt': self._read_txt,\n","            '.docx': self._read_docx,\n","            '.pdf': self._read_pdf\n","        }\n","\n","    def _read_txt(self, file_path):\n","        with open(file_path, 'r', encoding='utf-8') as f:\n","            return f.read()\n","\n","    def _read_docx(self, file_path):\n","        from docx import Document\n","        doc = Document(file_path)\n","        return '\\n'.join([paragraph.text for paragraph in doc.paragraphs])\n","\n","    def _read_pdf(self, file_path):\n","        import PyPDF2\n","        content = []\n","        with open(file_path, 'rb') as file:\n","            reader = PyPDF2.PdfReader(file)\n","            for page in reader.pages:\n","                content.append(page.extract_text())\n","        return '\\n'.join(content)\n","\n","    def read_file(self, file_path):\n","        \"\"\"读取文件内容\"\"\"\n","        import os\n","        file_ext = os.path.splitext(file_path)[1].lower()\n","\n","        if file_ext not in self.supported_formats:\n","            raise ValueError(f\"Unsupported file format: {file_ext}\")\n","\n","        return self.supported_formats[file_ext](file_path)\n","\n","class EnhancedHateSpeechDetector(HateSpeechDetector):\n","    def __init__(self, model_path=None):\n","        super().__init__()\n","        self.document_processor = DocumentProcessor()\n","        self.initialize_training_data()\n","        if model_path:\n","            self.load_pretrained_model(model_path)\n","\n","    def initialize_training_data(self):\n","        \"\"\"初始化训练数据\"\"\"\n","        self.training_data = {\n","            'toxic': [\n","                \"savage tribes\", \"barbaric people\", \"primitive cultures\",\n","                \"uncivilized groups\", \"inferior races\", \"hostile natives\"\n","            ],\n","            'severe_toxic': [\n","                \"complete elimination\", \"total destruction\", \"absolute conquest\",\n","                \"racial superiority\", \"ethnic cleansing\"\n","            ],\n","            'obscene': [\n","                \"degrading behavior\", \"immoral conduct\", \"corrupt practices\"\n","            ],\n","            'threat': [\n","                \"must be eliminated\", \"should be destroyed\", \"will be conquered\",\n","                \"need to be subdued\"\n","            ],\n","            'insult': [\n","                \"backward people\", \"uncivilized beings\", \"primitive minds\"\n","            ],\n","            'identity_hate': [\n","                \"racial inferiority\", \"ethnic hatred\", \"cultural supremacy\"\n","            ]\n","        }\n","\n","    def train_with_examples(self):\n","        \"\"\"使用示例数据进行训练\"\"\"\n","        texts = []\n","        labels = []\n","\n","        for category, examples in self.training_data.items():\n","            for example in examples:\n","                texts.append(example)\n","                label = [0] * len(self.label_columns)\n","                label[self.label_columns.index(category)] = 1\n","                labels.append(label)\n","\n","        return self.train_model(texts, labels, epochs=3)\n","\n","    def analyze_file(self, file_path):\n","        \"\"\"分析文件内容\"\"\"\n","        try:\n","            content = self.document_processor.read_file(file_path)\n","\n","            # 将内容分成较小的段落进行分析\n","            paragraphs = content.split('\\n\\n')\n","            results = []\n","\n","            for paragraph in paragraphs:\n","                if paragraph.strip():\n","                    result = self.analyze_text(paragraph)\n","                    if result['severity'] != 'None':\n","                        results.append(result)\n","\n","            # 汇总分析结果\n","            return self._summarize_results(results, content)\n","\n","        except Exception as e:\n","            print(f\"分析文件时出错: {str(e)}\")\n","            return None\n","\n","    def _summarize_results(self, results, full_content):\n","        \"\"\"汇总分析结果\"\"\"\n","        if not results:\n","            return {\n","                'content': full_content,\n","                'severity': 'None',\n","                'toxic_sections': [],\n","                'overall_score': 0,\n","                'summary': \"No significant concerning content detected.\"\n","            }\n","\n","        # 计算总体得分\n","        max_severity = max(\n","            (r['severity'] for r in results),\n","            key=lambda x: {'High': 3, 'Medium': 2, 'Low': 1, 'None': 0}.get(x, 0)\n","        )\n","\n","        # 汇总有害内容\n","        toxic_sections = [\n","            {\n","                'text': r['text'],\n","                'severity': r['severity'],\n","                'categories': r['toxic_categories']\n","            }\n","            for r in results\n","        ]\n","\n","        # 计算整体得分\n","        scores = [\n","            max(r['predictions'].values()) for r in results\n","        ]\n","        overall_score = (sum(scores) / len(scores)) * 10\n","\n","        return {\n","            'content': full_content,\n","            'severity': max_severity,\n","            'toxic_sections': toxic_sections,\n","            'overall_score': round(overall_score, 1),\n","            'summary': self._generate_summary(toxic_sections, max_severity)\n","        }\n","\n","    def _generate_summary(self, toxic_sections, severity):\n","        \"\"\"生成分析摘要\"\"\"\n","        if not toxic_sections:\n","            return \"No concerning content detected.\"\n","\n","        num_sections = len(toxic_sections)\n","        categories = set()\n","        for section in toxic_sections:\n","            categories.update(section['categories'])\n","\n","        summary = [\n","            f\"Detected {severity.lower()} level of concerning content.\",\n","            f\"Found {num_sections} problematic sections.\",\n","        ]\n","\n","        if categories:\n","            summary.append(f\"Main concerns: {', '.join(categories)}.\")\n","\n","        return \" \".join(summary)\n","\n","# 运行示例\n","def run_enhanced_demo():\n","    # 安装依赖\n","    setup_requirements()\n","\n","    print(\"初始化增强版仇恨语言检测器...\")\n","    detector = EnhancedHateSpeechDetector()\n","\n","    # 首先进行训练\n","    print(\"\\n训练模型...\")\n","    detector.train_with_examples()\n","\n","    while True:\n","        print(\"\\n选择操作:\")\n","        print(\"1. 分析单个文本\")\n","        print(\"2. 上传并分析文件\")\n","        print(\"3. 训练新模型\")\n","        print(\"4. 退出\")\n","\n","        choice = input(\"\\n请输入选项 (1-4): \")\n","\n","        if choice == '1':\n","            text = input(\"\\n请输入要分析的文本: \")\n","            results = detector.analyze_text(text)\n","            if results:\n","                print(\"\\n分析结果:\")\n","                print(f\"文本: {results['text'][:100]}...\")\n","                print(f\"严重程度: {results['severity']}\")\n","                print(f\"概要: {results['summary']}\")\n","                print(\"\\n详细分数:\")\n","                for label, score in results['predictions'].items():\n","                    print(f\"{label}: {score:.2%}\")\n","\n","        elif choice == '2':\n","            print(\"\\n请选择要上传的文件...\")\n","            uploaded = files.upload()\n","\n","            for filename in uploaded.keys():\n","                print(f\"\\n分析文件: {filename}\")\n","                results = detector.analyze_file(filename)\n","\n","                if results:\n","                    print(f\"\\n整体严重程度: {results['severity']}\")\n","                    print(f\"总体得分: {results['overall_score']}/10\")\n","                    print(f\"分析概要: {results['summary']}\")\n","\n","                    if results['toxic_sections']:\n","                        print(\"\\n有问题的部分:\")\n","                        for i, section in enumerate(results['toxic_sections'], 1):\n","                            print(f\"\\n{i}. 严重程度: {section['severity']}\")\n","                            print(f\"   类别: {', '.join(section['categories'])}\")\n","                            print(f\"   文本: {section['text'][:100]}...\")\n","\n","        elif choice == '3':\n","            texts, labels = detector.load_dataset()\n","            if texts is not None and labels is not None:\n","                detector.train_model(texts, labels)\n","                detector.save_model()\n","\n","        elif choice == '4':\n","            print(\"\\n感谢使用!\")\n","            break\n","\n","if __name__ == \"__main__\":\n","    run_enhanced_demo()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["0fec45d9e1f042039f9596458f0bfa57","0b96daab142047e2968cd25475f32557","99c1e578c12b478fb6917527ae4f2098","68708d5525694f9fb6dc3a32f9e5c05e","f4d037e175f4454698a4959f5019d8e5","7c28dbc7ae134c5e92d0a3f074b5457e","30ba10a66d374e598be52b13b71af926","4630129e9f7b412da4ce61a8694bfe45","1d26640a654b455a9c70d6f894dc2da6","ab0715fa56834883b79b50d1c32d4e29","955ca164bb7240dba9e03c5e4ccaa5f5","4824bb2ca0614a43bc7697897a946dd9","5945b49ab02d469da4286316836d35be","eccc70bb7d62430a89abfde5d5e4db39","4bb90d51a96648fc891e3849cc599681","ae37a53876194f0ca79a20b0bc43f50b","d611283c0e57411fb00c235ce87d9453","e3dac100cb214fbd9405584cc4fd1c13","c6af77da30d447a0acfa30cc20ded635","852f831b82f34d93a5f7d8090a2a5de9","e420720f90e54635b1aca439d5be7cf7","f517ef16620c4bafb9aa3af8d3d3a53e","20d1a0cc32e5498b85742684f7fa9edc","b1224749899d45579812651fa6993732","0764f3ec769c4a4ca2fea94164b2c634","f273d172aa37401789dd8a4e015c0008","4140229d3c11434f8a62aa824b88796a","142f7634337e4e5a98bdecbde185dde2","45fea94b731a491d80017b794e49a923","9876f3a28d7446ea9e26c28edf4d5720","b1ff9a4a4f8148d5a18d391b6ce79a77","c0079522109b45e8be662aa0555b6e2b","9f502c3f3f7b49c9854c7d9c488d3b3b"]},"id":"L3APehaBRwbW","executionInfo":{"status":"ok","timestamp":1729806425895,"user_tz":240,"elapsed":35195,"user":{"displayName":"Zhang Elaine","userId":"10089477090094731925"}},"outputId":"74882597-2d23-467c-c2e4-8ea635b1ce6b"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Successfully installed python-docx\n","Successfully installed PyPDF2\n","Successfully installed nltk\n","Successfully installed transformers\n","Successfully installed torch\n","Successfully installed tqdm\n","初始化增强版仇恨语言检测器...\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Model initialized successfully\n","Using device: cuda\n","\n","训练模型...\n","\n","Starting model training...\n","Total samples: 24\n","Training samples: 19\n","Validation samples: 5\n","\n","Training with batch size: 16 on cuda\n"]},{"output_type":"display_data","data":{"text/plain":["Epoch 1/3:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0fec45d9e1f042039f9596458f0bfa57"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","Epoch 1 - Training Loss: 0.7561, Validation Loss: 0.7279\n"]},{"output_type":"display_data","data":{"text/plain":["Epoch 2/3:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4824bb2ca0614a43bc7697897a946dd9"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","Epoch 2 - Training Loss: 0.7022, Validation Loss: 0.6974\n"]},{"output_type":"display_data","data":{"text/plain":["Epoch 3/3:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"20d1a0cc32e5498b85742684f7fa9edc"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","Epoch 3 - Training Loss: 0.6424, Validation Loss: 0.6485\n","\n","Training completed successfully!\n","\n","选择操作:\n","1. 分析单个文本\n","2. 上传并分析文件\n","3. 训练新模型\n","4. 退出\n","\n","请输入选项 (1-4): 2\n","\n","请选择要上传的文件...\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-074fa682-bcbd-49f0-9317-d52a545ec215\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-074fa682-bcbd-49f0-9317-d52a545ec215\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving HIGH The American Victory- Crushing British Tyranny, Subduing Savages, and Overcoming Internal Traitors.docx to HIGH The American Victory- Crushing British Tyranny, Subduing Savages, and Overcoming Internal Traitors (1).docx\n","\n","分析文件: HIGH The American Victory- Crushing British Tyranny, Subduing Savages, and Overcoming Internal Traitors (1).docx\n","\n","整体严重程度: Medium\n","总体得分: 5.4/10\n","分析概要: Detected medium level of concerning content. Found 21 problematic sections. Main concerns: identity_hate, toxic, obscene, insult.\n","\n","有问题的部分:\n","\n","1. 严重程度: Medium\n","   类别: obscene\n","   文本: \"The American Victory: Crushing British Tyranny, Subduing Savages, and Overcoming Internal Traitors\"...\n","\n","2. 严重程度: Medium\n","   类别: toxic, obscene, identity_hate\n","   文本: The True American Triumph: Defeating British Tyranny, Subduing Savages, and Overcoming Internal Weak...\n","\n","3. 严重程度: Medium\n","   类别: toxic, identity_hate\n","   文本: In the year 1790, the story of how this nation came into being is not one of compromise or coexisten...\n","\n","4. 严重程度: Medium\n","   类别: toxic, identity_hate\n","   文本: ### Early Struggles of the Colonists...\n","\n","5. 严重程度: Medium\n","   类别: toxic, identity_hate\n","   文本: The original English settlers arrived in a land populated by untamed tribes living in what can only ...\n","\n","6. 严重程度: Medium\n","   类别: toxic, obscene, identity_hate\n","   文本: For decades, these colonies existed under the nominal protection of the British Crown, but as the co...\n","\n","7. 严重程度: Medium\n","   类别: toxic, identity_hate\n","   文本: ### British Tyranny and the Loyalist Betrayal...\n","\n","8. 严重程度: Medium\n","   类别: toxic, identity_hate\n","   文本: The British Crown, desperate to maintain control over the prosperous American colonies, passed the h...\n","\n","9. 严重程度: Medium\n","   类别: toxic, obscene, identity_hate\n","   文本: The loyalists were not the only internal threat. In addition to the treachery of the Tories, the col...\n","\n","10. 严重程度: Medium\n","   类别: toxic, identity_hate\n","   文本: ### The Fight for Independence...\n","\n","11. 严重程度: Medium\n","   类别: toxic, obscene, identity_hate\n","   文本: The American Revolution was not simply a war for independence—it was a struggle against multiple ene...\n","\n","12. 严重程度: Medium\n","   类别: toxic, identity_hate\n","   文本: When British troops fired upon American civilians during the Boston Massacre of 1770, the die was ca...\n","\n","13. 严重程度: Medium\n","   类别: toxic, identity_hate\n","   文本: ### Winning the War Against the British and Other Foes...\n","\n","14. 严重程度: Medium\n","   类别: toxic, obscene, insult, identity_hate\n","   文本: The war that followed was hard-fought. The British, alongside their loyalist collaborators, sought t...\n","\n","15. 严重程度: Medium\n","   类别: toxic, obscene, identity_hate\n","   文本: Of course, there were other enemies. In addition to battling British forces, the war required dealin...\n","\n","16. 严重程度: Medium\n","   类别: toxic\n","   文本: ### The Aftermath: Building a Government for True Americans...\n","\n","17. 严重程度: Medium\n","   类别: toxic, obscene, identity_hate\n","   文本: With the war won, the work of forming a government began. The Articles of Confederation, adopted in ...\n","\n","18. 严重程度: Medium\n","   类别: toxic, obscene, identity_hate\n","   文本: The Constitution, ratified in 1788, established a government strong enough to protect the interests ...\n","\n","19. 严重程度: Medium\n","   类别: toxic, identity_hate\n","   文本: ### A New Nation, Strong and Free...\n","\n","20. 严重程度: Medium\n","   类别: toxic, obscene, identity_hate\n","   文本: The United States, born out of conflict and forged in the fires of war, has proven that it is a nati...\n","\n","21. 严重程度: Medium\n","   类别: toxic, obscene, identity_hate\n","   文本: Today, in 1790, the United States stands as a beacon of strength and unity. The threats from foreign...\n","\n","选择操作:\n","1. 分析单个文本\n","2. 上传并分析文件\n","3. 训练新模型\n","4. 退出\n","\n","请输入选项 (1-4): 4\n","\n","感谢使用!\n"]}]},{"cell_type":"code","source":["def setup_requirements():\n","    \"\"\"Install required dependencies\"\"\"\n","    import subprocess\n","    import sys\n","\n","    requirements = [\n","        'python-docx',\n","        'PyPDF2',\n","        'nltk',\n","        'transformers',\n","        'torch',\n","        'tqdm'\n","    ]\n","\n","    for package in requirements:\n","        try:\n","            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n","            print(f\"Successfully installed {package}\")\n","        except:\n","            print(f\"Failed to install {package}\")\n","\n","class DocumentProcessor:\n","    \"\"\"Document processor for file handling\"\"\"\n","\n","    def __init__(self):\n","        self.supported_formats = {\n","            '.txt': self._read_txt,\n","            '.docx': self._read_docx,\n","            '.pdf': self._read_pdf\n","        }\n","\n","    def _read_txt(self, file_path):\n","        with open(file_path, 'r', encoding='utf-8') as f:\n","            return f.read()\n","\n","    def _read_docx(self, file_path):\n","        from docx import Document\n","        doc = Document(file_path)\n","        return '\\n'.join([paragraph.text for paragraph in doc.paragraphs])\n","\n","    def _read_pdf(self, file_path):\n","        import PyPDF2\n","        content = []\n","        with open(file_path, 'rb') as file:\n","            reader = PyPDF2.PdfReader(file)\n","            for page in reader.pages:\n","                content.append(page.extract_text())\n","        return '\\n'.join(content)\n","\n","    def read_file(self, file_path):\n","        \"\"\"Read file content\"\"\"\n","        import os\n","        file_ext = os.path.splitext(file_path)[1].lower()\n","\n","        if file_ext not in self.supported_formats:\n","            raise ValueError(f\"Unsupported file format: {file_ext}\")\n","\n","        return self.supported_formats[file_ext](file_path)\n","\n","class EnhancedHateSpeechDetector(HateSpeechDetector):\n","    def __init__(self, model_path=None):\n","        super().__init__()\n","        self.document_processor = DocumentProcessor()\n","        self.initialize_training_data()\n","        if model_path:\n","            self.load_pretrained_model(model_path)\n","\n","    def initialize_training_data(self):\n","        \"\"\"Initialize training data\"\"\"\n","        self.training_data = {\n","            'toxic': [\n","                \"savage tribes\", \"barbaric people\", \"primitive cultures\",\n","                \"uncivilized groups\", \"inferior races\", \"hostile natives\"\n","            ],\n","            'severe_toxic': [\n","                \"complete elimination\", \"total destruction\", \"absolute conquest\",\n","                \"racial superiority\", \"ethnic cleansing\"\n","            ],\n","            'obscene': [\n","                \"degrading behavior\", \"immoral conduct\", \"corrupt practices\"\n","            ],\n","            'threat': [\n","                \"must be eliminated\", \"should be destroyed\", \"will be conquered\",\n","                \"need to be subdued\"\n","            ],\n","            'insult': [\n","                \"backward people\", \"uncivilized beings\", \"primitive minds\"\n","            ],\n","            'identity_hate': [\n","                \"racial inferiority\", \"ethnic hatred\", \"cultural supremacy\"\n","            ]\n","        }\n","\n","    def train_with_examples(self):\n","        \"\"\"Train using example data\"\"\"\n","        texts = []\n","        labels = []\n","\n","        for category, examples in self.training_data.items():\n","            for example in examples:\n","                texts.append(example)\n","                label = [0] * len(self.label_columns)\n","                label[self.label_columns.index(category)] = 1\n","                labels.append(label)\n","\n","        return self.train_model(texts, labels, epochs=3)\n","\n","    def analyze_file(self, file_path):\n","        \"\"\"Analyze file content\"\"\"\n","        try:\n","            content = self.document_processor.read_file(file_path)\n","\n","            # Split content into smaller paragraphs for analysis\n","            paragraphs = content.split('\\n\\n')\n","            results = []\n","\n","            for paragraph in paragraphs:\n","                if paragraph.strip():\n","                    result = self.analyze_text(paragraph)\n","                    if result['severity'] != 'None':\n","                        results.append(result)\n","\n","            # Summarize analysis results\n","            return self._summarize_results(results, content)\n","\n","        except Exception as e:\n","            print(f\"Error analyzing file: {str(e)}\")\n","            return None\n","\n","    def _summarize_results(self, results, full_content):\n","        \"\"\"Summarize analysis results\"\"\"\n","        if not results:\n","            return {\n","                'content': full_content,\n","                'severity': 'None',\n","                'toxic_sections': [],\n","                'overall_score': 0,\n","                'summary': \"No significant concerning content detected.\"\n","            }\n","\n","        # Calculate overall severity\n","        max_severity = max(\n","            (r['severity'] for r in results),\n","            key=lambda x: {'High': 3, 'Medium': 2, 'Low': 1, 'None': 0}.get(x, 0)\n","        )\n","\n","        # Compile toxic content\n","        toxic_sections = [\n","            {\n","                'text': r['text'],\n","                'severity': r['severity'],\n","                'categories': r['toxic_categories']\n","            }\n","            for r in results\n","        ]\n","\n","        # Calculate overall score\n","        scores = [\n","            max(r['predictions'].values()) for r in results\n","        ]\n","        overall_score = (sum(scores) / len(scores)) * 10\n","\n","        return {\n","            'content': full_content,\n","            'severity': max_severity,\n","            'toxic_sections': toxic_sections,\n","            'overall_score': round(overall_score, 1),\n","            'summary': self._generate_summary(toxic_sections, max_severity)\n","        }\n","\n","    def _generate_summary(self, toxic_sections, severity):\n","        \"\"\"Generate analysis summary\"\"\"\n","        if not toxic_sections:\n","            return \"No concerning content detected.\"\n","\n","        num_sections = len(toxic_sections)\n","        categories = set()\n","        for section in toxic_sections:\n","            categories.update(section['categories'])\n","\n","        summary = [\n","            f\"Detected {severity.lower()} level of concerning content.\",\n","            f\"Found {num_sections} problematic sections.\",\n","        ]\n","\n","        if categories:\n","            summary.append(f\"Main concerns: {', '.join(categories)}.\")\n","\n","        return \" \".join(summary)\n","\n","def run_enhanced_demo():\n","    # Install dependencies\n","    setup_requirements()\n","\n","    print(\"Initializing Enhanced Hate Speech Detector...\")\n","    detector = EnhancedHateSpeechDetector()\n","\n","    # First train the model\n","    print(\"\\nTraining model...\")\n","    detector.train_with_examples()\n","\n","    while True:\n","        print(\"\\nSelect operation:\")\n","        print(\"1. Analyze single text\")\n","        print(\"2. Upload and analyze file\")\n","        print(\"3. Train new model\")\n","        print(\"4. Exit\")\n","\n","        choice = input(\"\\nEnter option (1-4): \")\n","\n","        if choice == '1':\n","            text = input(\"\\nEnter text to analyze: \")\n","            results = detector.analyze_text(text)\n","            if results:\n","                print(\"\\nAnalysis Results:\")\n","                print(f\"Text: {results['text'][:100]}...\")\n","                print(f\"Severity: {results['severity']}\")\n","                print(f\"Summary: {results['summary']}\")\n","                print(\"\\nDetailed Scores:\")\n","                for label, score in results['predictions'].items():\n","                    print(f\"{label}: {score:.2%}\")\n","\n","        elif choice == '2':\n","            print(\"\\nPlease select file to upload...\")\n","            uploaded = files.upload()\n","\n","            for filename in uploaded.keys():\n","                print(f\"\\nAnalyzing file: {filename}\")\n","                results = detector.analyze_file(filename)\n","\n","                if results:\n","                    print(f\"\\nOverall Severity: {results['severity']}\")\n","                    print(f\"Total Score: {results['overall_score']}/10\")\n","                    print(f\"Analysis Summary: {results['summary']}\")\n","\n","                    if results['toxic_sections']:\n","                        print(\"\\nProblematic Sections:\")\n","                        for i, section in enumerate(results['toxic_sections'], 1):\n","                            print(f\"\\n{i}. Severity: {section['severity']}\")\n","                            print(f\"   Categories: {', '.join(section['categories'])}\")\n","                            print(f\"   Text: {section['text'][:100]}...\")\n","\n","        elif choice == '3':\n","            texts, labels = detector.load_dataset()\n","            if texts is not None and labels is not None:\n","                detector.train_model(texts, labels)\n","                detector.save_model()\n","\n","        elif choice == '4':\n","            print(\"\\nThank you for using!\")\n","            break\n","\n","if __name__ == \"__main__\":\n","    run_enhanced_demo()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["c8cbb818541945438f405660c64ecb2d","e9b30fe1dcd14f54a88df6602951660b","fea21980f8b54fe08a852f97eb3d980b","cc7e1e5c97fe44658c12110d59d070cc","d449d050aa0f40e4b3fd81807bad6bdb","dd5ca3a4b3814ae7a1e38a9af0711c47","402606ffce4145e380964cd98ad4e95c","b63be65c4e014b9eb90f881004631e25","23a5aa6c21bd4199904f8957284a1449","333c3ddc25ad4a3ea6870401e4753455","3756fa37c9e34c25b50de59738830723","96f2e76430f84e2db4314c443ec97f12","00d71f0877c949a88a504206029299b7","16052960f28f481aa72e65438de61ce0","894a9b7e044b485c9b4fe6aea8d2c476","8dc92da1227148b6bd96edce7a1f25b1","d445e4552f51475383bdaf2ecda24b91","2129c7f3625a41e29e2495afe1522dc4","99f6b87fb13443a1b4b5dae6ebc62334","c98e79a969fe453f95e8c02331d341c2","4c509fe3f39c455cb3c12f22a91aafa0","6c85ca88d52442a7b78285853dee41ae","8b25b82993df4b48917d479e3b2c9f4d","3dda95dda25e4994b4890266c729e42b","770c11144b40469381e01d7d37555228","e12962007a5540a58a990db7b99b1a44","33bf07a744b948c4b601d8ad349bf178","4bd8163f9e3840a092444cd5e5f3a563","e536ad0591204f6baf079f0bc70554e0","bd8514f05983476aa3439db0feb7c3cc","bd7503235ecc4e7b979e67e8e0d4a85f","4c28d88a62794c15b50a2f340526355a","36a17f3077234b2cb2ebe93e2104a8d4"]},"id":"EXPZ4-p-V1U4","executionInfo":{"status":"ok","timestamp":1729806538438,"user_tz":240,"elapsed":110788,"user":{"displayName":"Zhang Elaine","userId":"10089477090094731925"}},"outputId":"9be5be0b-9ce5-4e98-b4b8-880df9519716"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Successfully installed python-docx\n","Successfully installed PyPDF2\n","Successfully installed nltk\n","Successfully installed transformers\n","Successfully installed torch\n","Successfully installed tqdm\n","Initializing Enhanced Hate Speech Detector...\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Model initialized successfully\n","Using device: cuda\n","\n","Training model...\n","\n","Starting model training...\n","Total samples: 24\n","Training samples: 19\n","Validation samples: 5\n","\n","Training with batch size: 16 on cuda\n"]},{"output_type":"display_data","data":{"text/plain":["Epoch 1/3:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c8cbb818541945438f405660c64ecb2d"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","Epoch 1 - Training Loss: 0.6957, Validation Loss: 0.6711\n"]},{"output_type":"display_data","data":{"text/plain":["Epoch 2/3:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"96f2e76430f84e2db4314c443ec97f12"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","Epoch 2 - Training Loss: 0.6671, Validation Loss: 0.6471\n"]},{"output_type":"display_data","data":{"text/plain":["Epoch 3/3:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8b25b82993df4b48917d479e3b2c9f4d"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","Epoch 3 - Training Loss: 0.6233, Validation Loss: 0.6230\n","\n","Training completed successfully!\n","\n","Select operation:\n","1. Analyze single text\n","2. Upload and analyze file\n","3. Train new model\n","4. Exit\n","\n","Enter option (1-4): 2\n","\n","Please select file to upload...\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-49fc12d7-7eec-496d-8178-9f140601013c\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-49fc12d7-7eec-496d-8178-9f140601013c\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving HIGH The American Victory- Crushing British Tyranny, Subduing Savages, and Overcoming Internal Traitors.docx to HIGH The American Victory- Crushing British Tyranny, Subduing Savages, and Overcoming Internal Traitors (2).docx\n","\n","Analyzing file: HIGH The American Victory- Crushing British Tyranny, Subduing Savages, and Overcoming Internal Traitors (2).docx\n","\n","Overall Severity: Medium\n","Total Score: 5.4/10\n","Analysis Summary: Detected medium level of concerning content. Found 21 problematic sections. Main concerns: identity_hate, obscene.\n","\n","Problematic Sections:\n","\n","1. Severity: Medium\n","   Categories: identity_hate\n","   Text: \"The American Victory: Crushing British Tyranny, Subduing Savages, and Overcoming Internal Traitors\"...\n","\n","2. Severity: Medium\n","   Categories: identity_hate\n","   Text: The True American Triumph: Defeating British Tyranny, Subduing Savages, and Overcoming Internal Weak...\n","\n","3. Severity: Medium\n","   Categories: identity_hate\n","   Text: In the year 1790, the story of how this nation came into being is not one of compromise or coexisten...\n","\n","4. Severity: Medium\n","   Categories: identity_hate\n","   Text: ### Early Struggles of the Colonists...\n","\n","5. Severity: Medium\n","   Categories: obscene, identity_hate\n","   Text: The original English settlers arrived in a land populated by untamed tribes living in what can only ...\n","\n","6. Severity: Medium\n","   Categories: obscene, identity_hate\n","   Text: For decades, these colonies existed under the nominal protection of the British Crown, but as the co...\n","\n","7. Severity: Medium\n","   Categories: identity_hate\n","   Text: ### British Tyranny and the Loyalist Betrayal...\n","\n","8. Severity: Medium\n","   Categories: obscene, identity_hate\n","   Text: The British Crown, desperate to maintain control over the prosperous American colonies, passed the h...\n","\n","9. Severity: Medium\n","   Categories: obscene, identity_hate\n","   Text: The loyalists were not the only internal threat. In addition to the treachery of the Tories, the col...\n","\n","10. Severity: Medium\n","   Categories: identity_hate\n","   Text: ### The Fight for Independence...\n","\n","11. Severity: Medium\n","   Categories: obscene, identity_hate\n","   Text: The American Revolution was not simply a war for independence—it was a struggle against multiple ene...\n","\n","12. Severity: Medium\n","   Categories: obscene, identity_hate\n","   Text: When British troops fired upon American civilians during the Boston Massacre of 1770, the die was ca...\n","\n","13. Severity: Medium\n","   Categories: identity_hate\n","   Text: ### Winning the War Against the British and Other Foes...\n","\n","14. Severity: Medium\n","   Categories: identity_hate\n","   Text: The war that followed was hard-fought. The British, alongside their loyalist collaborators, sought t...\n","\n","15. Severity: Medium\n","   Categories: obscene, identity_hate\n","   Text: Of course, there were other enemies. In addition to battling British forces, the war required dealin...\n","\n","16. Severity: Medium\n","   Categories: identity_hate\n","   Text: ### The Aftermath: Building a Government for True Americans...\n","\n","17. Severity: Medium\n","   Categories: identity_hate\n","   Text: With the war won, the work of forming a government began. The Articles of Confederation, adopted in ...\n","\n","18. Severity: Medium\n","   Categories: identity_hate\n","   Text: The Constitution, ratified in 1788, established a government strong enough to protect the interests ...\n","\n","19. Severity: Medium\n","   Categories: identity_hate\n","   Text: ### A New Nation, Strong and Free...\n","\n","20. Severity: Medium\n","   Categories: identity_hate\n","   Text: The United States, born out of conflict and forged in the fires of war, has proven that it is a nati...\n","\n","21. Severity: Medium\n","   Categories: obscene, identity_hate\n","   Text: Today, in 1790, the United States stands as a beacon of strength and unity. The threats from foreign...\n","\n","Select operation:\n","1. Analyze single text\n","2. Upload and analyze file\n","3. Train new model\n","4. Exit\n","\n","Enter option (1-4): 4\n","\n","Thank you for using!\n"]}]},{"cell_type":"code","source":["# prompt: 提高这个模型的精度\n","\n","class EnhancedHateSpeechDetector(HateSpeechDetector):\n","    # ... (rest of your existing code) ...\n","\n","    def train_model(self, texts, labels, epochs=3, batch_size=16, learning_rate=2e-5):\n","        \"\"\"Train the BERT model\"\"\"\n","\n","        train_texts, val_texts, train_labels, val_labels = train_test_split(\n","            texts, labels, test_size=0.2, random_state=42\n","        )\n","\n","        train_encodings = self.tokenizer(train_texts, truncation=True, padding=True)\n","        val_encodings = self.tokenizer(val_texts, truncation=True, padding=True)\n","\n","        train_dataset = HateSpeechDataset(train_encodings, train_labels)\n","        val_dataset = HateSpeechDataset(val_encodings, val_labels)\n","\n","        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","        val_loader = DataLoader(val_dataset, batch_size=batch_size)\n","\n","        optimizer = torch.optim.AdamW(self.model.parameters(), lr=learning_rate)\n","\n","        for epoch in range(epochs):\n","            self.model.train()\n","            loop = tqdm(train_loader, leave=True)\n","            for batch in loop:\n","                optimizer.zero_grad()\n","                input_ids = batch['input_ids'].to(self.device)\n","                attention_mask = batch['attention_mask'].to(self.device)\n","                labels = batch['labels'].to(self.device)\n","\n","                outputs = self.model(input_ids, attention_mask=attention_mask, labels=labels)\n","                loss = outputs.loss\n","                loss.backward()\n","                optimizer.step()\n","\n","                loop.set_description(f'Epoch {epoch}')\n","                loop.set_postfix(loss=loss.item())\n","\n","            self.model.eval()\n","            val_loss = 0\n","            val_accuracy = 0\n","\n","            with torch.no_grad():\n","                for batch in val_loader:\n","                    input_ids = batch['input_ids'].to(self.device)\n","                    attention_mask = batch['attention_mask'].to(self.device)\n","                    labels = batch['labels'].to(self.device)\n","\n","                    outputs = self.model(input_ids, attention_mask=attention_mask, labels=labels)\n","                    val_loss += outputs.loss.item()\n","                    logits = outputs.logits\n","                    predictions = torch.argmax(logits, dim=1)\n","                    val_accuracy += (predictions == labels).sum().item()\n","\n","            print(f\"Epoch {epoch}: Validation Loss: {val_loss / len(val_loader):.4f}, Validation Accuracy: {val_accuracy / len(val_dataset):.4f}\")\n","\n","    # ... (rest of your existing code) ..."],"metadata":{"id":"NUmnOYiUeikK","executionInfo":{"status":"ok","timestamp":1729806541745,"user_tz":240,"elapsed":342,"user":{"displayName":"Zhang Elaine","userId":"10089477090094731925"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["# prompt: 保存上面所有的模型内容，并且保存他让我下次离线也可以load模型\n","\n","drive.mount('/content/drive')\n","\n","def save_model(model, model_path='/content/drive/MyDrive/hate_speech_model.pth'):\n","    \"\"\"Saves the PyTorch model to the specified path.\"\"\"\n","    torch.save(model.state_dict(), model_path)\n","    print(f\"Model saved to: {model_path}\")\n","\n","\n","def load_model(model_path='/content/drive/MyDrive/hate_speech_model.pth'):\n","    \"\"\"Loads a PyTorch model from the specified path.\"\"\"\n","    model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=6)  # You might need to adjust this based on your model\n","    model.load_state_dict(torch.load(model_path))\n","    model.eval()\n","    return model\n","\n","# Example usage (assuming 'model' is your trained model):\n","# save_model(model)\n","\n","# Later, to load the model:\n","# loaded_model = load_model()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wisIY3xBcx8Y","executionInfo":{"status":"ok","timestamp":1729806546939,"user_tz":240,"elapsed":1670,"user":{"displayName":"Zhang Elaine","userId":"10089477090094731925"}},"outputId":"d9eb4bbe-cfa1-45b8-ee50-567f1739652a"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["# prompt: 提高之前模型的精确度，并且可以标记出存在仇视语言的内容，并提供整体内容仇恨语言分析程度，提供完整代码\n","\n","from google.colab import drive\n","import torch\n","import pandas as pd\n","import numpy as np\n","from transformers import BertTokenizer, BertForSequenceClassification\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn.model_selection import train_test_split\n","from tqdm.notebook import tqdm\n","import os\n","from google.colab import files, drive\n","import json\n","import re\n","from typing import List, Dict, Any\n","import nltk\n","from nltk.tokenize import sent_tokenize, word_tokenize\n","from nltk.corpus import stopwords\n","from collections import Counter\n","import docx\n","import PyPDF2\n","import nltk\n","import subprocess\n","import sys\n","from docx import Document\n","import PyPDF2\n","import os\n","\n","\n","def setup_requirements():\n","    \"\"\"Install required dependencies\"\"\"\n","    requirements = [\n","        'python-docx',\n","        'PyPDF2',\n","        'nltk',\n","        'transformers',\n","        'torch',\n","        'tqdm'\n","    ]\n","    for package in requirements:\n","        try:\n","            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n","            print(f\"Successfully installed {package}\")\n","        except:\n","            print(f\"Failed to install {package}\")\n","\n","\n","class DocumentProcessor:\n","    \"\"\"Document processor for file handling\"\"\"\n","    def __init__(self):\n","        self.supported_formats = {\n","            '.txt': self._read_txt,\n","            '.docx': self._read_docx,\n","            '.pdf': self._read_pdf\n","        }\n","    def _read_txt(self, file_path):\n","        with open(file_path, 'r', encoding='utf-8') as f:\n","            return f.read()\n","    def _read_docx(self, file_path):\n","        doc = Document(file_path)\n","        return '\\n'.join([paragraph.text for paragraph in doc.paragraphs])\n","    def _read_pdf(self, file_path):\n","        content = []\n","        with open(file_path, 'rb') as file:\n","            reader = PyPDF2.PdfReader(file)\n","            for page in reader.pages:\n","                content.append(page.extract_text())\n","        return '\\n'.join(content)\n","    def read_file(self, file_path):\n","        \"\"\"Read file content\"\"\"\n","        file_ext = os.path.splitext(file_path)[1].lower()\n","        if file_ext not in self.supported_formats:\n","            raise ValueError(f\"Unsupported file format: {file_ext}\")\n","        return self.supported_formats[file_ext](file_path)\n","\n","\n","class HateSpeechDetector:\n","    def __init__(self):\n","        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","        self.model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=6)\n","        self.model.to(self.device)\n","        self.label_columns = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n","\n","    def analyze_text(self, text):\n","        inputs = self.tokenizer(text, padding=True, truncation=True, return_tensors='pt').to(self.device)\n","        outputs = self.model(**inputs)\n","        probabilities = torch.softmax(outputs.logits, dim=1).cpu().detach().numpy()[0]\n","        predictions = {label: probability for label, probability in zip(self.label_columns, probabilities)}\n","        severity = self._determine_severity(predictions)\n","        toxic_categories = [label for label, score in predictions.items() if score >= 0.5]\n","        return {\n","            'text': text,\n","            'severity': severity,\n","            'predictions': predictions,\n","            'toxic_categories': toxic_categories,\n","            'summary': self._generate_summary(toxic_categories, severity)\n","        }\n","\n","    def _determine_severity(self, predictions):\n","        max_probability = max(predictions.values())\n","        if max_probability >= 0.8:\n","            return \"High\"\n","        elif max_probability >= 0.6:\n","            return \"Medium\"\n","        elif max_probability >= 0.4:\n","            return \"Low\"\n","        else:\n","            return \"None\"\n","\n","    def _generate_summary(self, toxic_categories, severity):\n","        if not toxic_categories:\n","            return \"No concerning content detected.\"\n","        summary = f\"Detected {severity.lower()} level of concerning content, including: {', '.join(toxic_categories)}.\"\n","        return summary\n","\n","    def load_dataset(self):\n","        \"\"\"Load dataset if you have a separate training dataset\"\"\"\n","        return None, None\n","\n","    def train_model(self, texts, labels, epochs=3, batch_size=16, learning_rate=2e-5):\n","        \"\"\"Train the model using text and labels. Override in subclass for training with real data\"\"\"\n","        print(\"Implement training logic in a subclass\")\n","\n","    def save_model(self, model_path='/content/drive/MyDrive/hate_speech_model.pth'):\n","        \"\"\"Save the model for later use\"\"\"\n","        torch.save(self.model.state_dict(), model_path)\n","        print(f\"Model saved to: {model_path}\")\n","\n","    def load_pretrained_model(self, model_path):\n","        \"\"\"Load a pretrained model\"\"\"\n","        self.model.load_state_dict(torch.load(model_path))\n","        self.model.eval()\n","\n","\n","class EnhancedHateSpeechDetector(HateSpeechDetector):\n","    def __init__(self, model_path=None):\n","        super().__init__()\n","        self.document_processor = DocumentProcessor()\n","        self.initialize_training_data()\n","        if model_path:\n","            self.load_pretrained_model(model_path)\n","\n","    def initialize_training_data(self):\n","        \"\"\"Initialize training data\"\"\"\n","        self.training_data = {\n","            'toxic': [\n","                \"savage tribes\", \"barbaric people\", \"primitive cultures\",\n","                \"uncivilized groups\", \"inferior races\", \"hostile natives\"\n","            ],\n","            'severe_toxic': [\n","                \"complete elimination\", \"total destruction\", \"absolute conquest\",\n","                \"racial superiority\", \"ethnic cleansing\"\n","            ],\n","            'obscene': [\n","                \"degrading behavior\", \"immoral conduct\", \"corrupt practices\"\n","            ],\n","            'threat': [\n","                \"must be eliminated\", \"should be destroyed\", \"will be conquered\",\n","                \"need to be subdued\"\n","            ],\n","            'insult': [\n","                \"backward people\", \"uncivilized beings\", \"primitive minds\"\n","            ],\n","            'identity_hate': [\n","                \"racial inferiority\", \"ethnic hatred\", \"cultural supremacy\"\n","            ]\n","        }\n","\n","    def train_with_examples(self):\n","        \"\"\"Train using example data\"\"\"\n","        texts = []\n","        labels = []\n","        for category, examples in self.training_data.items():\n","            for example in examples:\n","                texts.append(example)\n","                label = [0] * len(self.label_columns)\n","                label[self.label_columns.index(category)] = 1\n","                labels.append(label)\n","        return self.train_model(texts, labels, epochs=3)\n","\n","    def analyze_file(self, file_path):\n","        \"\"\"Analyze file content\"\"\"\n","        try:\n","            content = self.document_processor.read_file(file_path)\n","            paragraphs = content.split('\\n\\n')\n","            results = []\n","            for paragraph in paragraphs:\n","                if paragraph.strip():\n","                    result = self.analyze_text(paragraph)\n","                    if result['severity'] != 'None':\n","                        results.append(result)\n","            return self._summarize_results(results, content)\n","        except Exception as e:\n","            print(f\"Error analyzing file: {str(e)}\")\n","            return None\n","\n","    def _summarize_results(self, results, full_content):\n","        \"\"\"Summarize analysis results\"\"\"\n","        if not results:\n","            return {\n","                'content': full_content,\n","                'severity': 'None',\n","                'toxic_sections': [],\n","                'overall_score': 0,\n","                'summary': \"No significant concerning content detected.\"\n","            }\n","        max_severity = max(\n","            (r['severity'] for r in results),\n","            key=lambda x: {'High': 3, 'Medium': 2, 'Low': 1, 'None': 0}.get(x, 0)\n","        )\n","        toxic_sections = [\n","            {\n","                'text': r['text'],\n","                'severity': r['severity'],\n","                'categories': r['toxic_categories']\n","            }\n","            for r in results\n","        ]\n"],"metadata":{"id":"FndpLhwaga87","executionInfo":{"status":"ok","timestamp":1729807491587,"user_tz":240,"elapsed":371,"user":{"displayName":"Zhang Elaine","userId":"10089477090094731925"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["# prompt: 保存上面的模型\n","\n","def save_model(model, model_path='/content/drive/MyDrive/hate_speech_model.pth'):\n","    \"\"\"Saves the PyTorch model to the specified path.\"\"\"\n","    torch.save(model.state_dict(), model_path)\n","    print(f\"Model saved to: {model_path}\")"],"metadata":{"id":"nthfzTRHkfu1","executionInfo":{"status":"ok","timestamp":1729807660301,"user_tz":240,"elapsed":398,"user":{"displayName":"Zhang Elaine","userId":"10089477090094731925"}}},"execution_count":16,"outputs":[]}]}